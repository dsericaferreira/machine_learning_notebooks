{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> ☕️ Passos: </h2>\n",
    "\n",
    "<h3> Import Libraries </h3>\n",
    "<h3> Extração dos dados. </h3>\n",
    "<h3> Visualização dos dados.  </h3>\n",
    "<h3> Random Forest </h3>\n",
    "<h3> Decision Tree </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se não forem encontrados módulos, você pode via terminal usar o comando\n",
    "# pip install -r requirements.txt \n",
    "# Ele vai instalar todos os módulos contidos no arquivo de requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_check(X):\n",
    "    df = pd.read_csv(X)\n",
    "    print('Total of null records   :', df.isnull().sum())\n",
    "    print('Total of NaN records   :', df.isna().sum())\n",
    "    print('\\n\\nDataset description   :\\n\\n', df.describe())\n",
    "    print('\\n\\nDataset shape   :\\n', df.shape)\n",
    "    \n",
    "    for i in df.columns:    \n",
    "        print('Unique values of {:10}:'.format(i))\n",
    "\n",
    "        #display('Counting Unique Values   of', df[i].value_counts())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of null records   : vhigh      0\n",
      "vhigh.1    0\n",
      "2          0\n",
      "2.1        0\n",
      "small      0\n",
      "low        0\n",
      "unacc      0\n",
      "dtype: int64\n",
      "Total of NaN records   : vhigh      0\n",
      "vhigh.1    0\n",
      "2          0\n",
      "2.1        0\n",
      "small      0\n",
      "low        0\n",
      "unacc      0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Dataset description   :\n",
      "\n",
      "        vhigh vhigh.1      2   2.1 small   low  unacc\n",
      "count   1727    1727   1727  1727  1727  1727   1727\n",
      "unique     4       4      4     3     3     3      4\n",
      "top      med     med  5more  more   big   med  unacc\n",
      "freq     432     432    432   576   576   576   1209\n",
      "\n",
      "\n",
      "Dataset shape   :\n",
      " (1727, 7)\n",
      "Unique values of vhigh     :\n",
      "Unique values of vhigh.1   :\n",
      "Unique values of 2         :\n",
      "Unique values of 2.1       :\n",
      "Unique values of small     :\n",
      "Unique values of low       :\n",
      "Unique values of unacc     :\n"
     ]
    }
   ],
   "source": [
    "# Extraindo os dados utilizando uma função que generaliza a inspeção do dataset. \n",
    "\n",
    "data_cars = read_check('car_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
